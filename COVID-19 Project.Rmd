---
title: "COVID-19 Project"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})

author: "Xinxin Luo"
date: "4/18/2020"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
```

Load the data and Explore the data
```{r}
data <- read.csv("Book2.csv") # load data
str(data) # see all columns type and values
data[data==""] <- NA #treat all blank values as missing elements of the data matrix
```

Find correlation between age, and incubation (derived)

```{r}
data$incubation <- as.numeric(
                    as.Date(as.character(data$symptom_onset),format = "%m/%d/%Y") - as.Date(as.character(data$exposure_start), format = "%m/%d/%Y") 
                              ) # derive variable incubation = symptom_onset date - exposure_start date
```

Normalized the numeric variables 
```{r}

normalize <- function(x){
  return((x-min(x))/(max(x)-min(x))) } # normalize function created
data1 <- data[,c(9,25)] #age and incubation selected
data1 <- na.omit(data1)
data1_n <- as.data.frame(lapply(data1,normalize))
summary(data1_n)# check if it is normalized

```
Find correlation between age, and incubation (derived)
```{r}

library(ggplot2)
ggplot(data=data1_n) +
    geom_point(mapping = aes(x=age, y=incubation)) +
  geom_smooth(mapping = aes(x=age, y=incubation))# no obvious correlation between age and incubation period.

cor(data1_n$age,data1_n$incubation,use="complete.obs", method = "pearson") # 0.3 indicates 1 weak positive linear relationships between age and incubation period. 
psych::pairs.panels(data1_n[,c(1,2)]) # correlation visualization between age and incubation. 

```


```{r}

ggplot(data, aes(x=country, fill=country)) + 
    ylim(0,1800) +
    geom_bar() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

Predict the probability of death using different prediction models: 
MODEL 1: multiple regression model - lm from stats package 
```{r}

library(data.table)

data$death<- as.numeric(fifelse(data$death==0, 0, 1, na=NA)) # changing death to numeric variable

library(stringr)

for (i in 1:nrow(data)){
  data$n_symptom[i] <- (str_count(data$symptom[i], ',')+1)
} # assuming more number of symptoms there are, more severe the problem is. 

data$gender1 <- ifelse(data$gender!="female"&
                        data$gender!="male",
                    NA,data$gender); 

for (i in 1:nrow(data)){
  data$gender1[i] <- (data$gender1[i]-3)
}; # 0 is female; 1 is male 

lm <-lm(death~case_in_country+country+gender1+age+incubation+n_symptom,data) # creating multiple linear regression model

summary(lm); # model r-squared value is around 15%, which is quite small; only 15% of variances are explained by the model and 5% of standard deviation are explained. 

test <- data.frame(case_in_country=210, country="USA",gender1=0, age=70, n_symptom=6, incubation=4) # make a prediction with a novel patient

test$death.p <- predict(lm,test)
test$death.p 

# the likelihood of patient death is close to 0. 

```

MODEL 2 K-Means Clustering 
(to discover any unknown subtypes of patients who have being diagnosed with COVID)

```{r}

# removing unnecessary columns
interests<- data[,c(2,9,25,26)] 
# The kmeans() function requires a data frame containing only numeric data and a parameter specifying the desired number of clusters. We will choose only 4 features that represents a patient with COVID-19. 

# removing non-existing values
interests <- na.omit(interests)

# apply as.interger to all vectors
data.interest_int <- as.data.frame(lapply(interests,as.integer))
summary(data.interest_int)

# apply z-score standardization
data_int_z <- as.data.frame(lapply(data.interest_int,scale))

# Set the seed, so results are reproducible
set.seed(1234)

# create index for randomly selecting 75% rows of the original data set
index <- sample.int(n = nrow(interests), size = floor(.75*nrow(interests)), replace = F)

# create training dataset, which accounts for 75% of the data set
data.train_z <- data.interest_int[index, ]
# create testing dataset, which accounts for 25% of the data set
data.test_z  <- data.interest_int[-index, ]

# set specific starting point for k-means algorithm
RNGversion("3.5.2")

# building clustering model
patient_clusters <- kmeans(data.interest_int,3) # 3 for 3 clusters

```

Evaluating Model 2- Check machine learning performance evaluation for k-means clustering 
```{r}

# check size of all 3 groups
patient_clusters$size

# examine cluster centroids
patient_clusters$centers

# Comment: we can see that group 2 and 3 are mostly alders, and group 1 is younger people. For elders has less incubation period reported than young adults, compared in group 1. For patients from countrys that have more cases, the incubation period is much shorter as well. It seems like the numbers of cases encouraged patients to seek for medical attention and increased health care awareness; this could explain why the incubation period is shorter in countries with more cases. 
```
Visualize the clusters
```{r}

# load necessary package 
library(factoextra)

# function fviz_cluster can be used to visualize the 3 clusters created previously.
fviz_cluster(patient_clusters,data.interest_int,ellipse.type = "norm")

# Comment: Given the graph, we would have a clear dipictions of 3 groups of patients related to COVID-19. Based on these profiles, the doctor could anticipate the days of symptoms onset after the patient is exposed to the high hazardous factors and how long symptoms would. 
# shortcoming of the model: after missing values being omitted, there are too little data points available for a good evaluation in group 2. 
```

Model 3 - kNN algorithm
```{r}
# load necessary packages
library(caret)
library(ISLR)

# removing unnecessary columns
interests<- data[,c(2,9,19,20,26,27)]  # includes columns: case_in_country, age, from.wuhan, death, n_symptom, and gender1. 

# removing non-existing values
interests <- na.omit(interests)

# normalize data
data_n <- as.data.frame(lapply(interests,normalize))
summary(data_n)# check if it is normalized

# set seed
set.seed(12378)

# create index for randomly selecting 75% rows of the original data set
index <- sample.int(n = nrow(data_n), size = floor(.75*nrow(data_n)), replace = F)

# create training dataset, which accounts for 75% of the data set
data.train <- data_n[index, ]
# create testing dataset, which accounts for 25% of the data set
data.test  <- data_n[-index, ]

# column bind labels to the normalized test and train dataset
data_train_label <- as.data.frame(data.train$death)
data_test_label <- as.data.frame(data.test$death)
names(data_train_label) <- "death"
names(data_test_label) <- "death"
data_train1 <- cbind(data_train_label,data.train)
data_test1 <- cbind(data_test_label,data.test)
```

```{r}

# set up control object which controls the computational nuances of the train function. 
ctrl <- trainControl(method="repeatedcv", repeats = 3)  #Cross-Validated (10 fold, repeated 3 times) 

# training the model
knnFit <- train(death~., data=data_train1,method="knn",trControl=ctrl,preProcess=c("center","scale"),tuneLength=2)

# output of the kNN fit
knnFit
```


```{r}
# plotting yields number of neighbours vs accuracy (based on repeated cross valdiation)
 plot(knnFit)

# predict using testing data
knnPredict <- predict(knnFit,newdata=data_test1)
knnPredict <- as.factor(ifelse(knnPredict>0,1,0))
knnPredict

#data_test1$death <- as.factor(data_test1$death)
data_test1$death
death_label <- as.factor(data_test1$death)
# use confusion matrix to calculate accuracy for caret algorithm
confusionMatrix(knnPredict,death_label)
mean(knnPredict==death_label)

# comment: the accuracy for caret is 86%. 
```

Comparison of models
```{r}
# According to evaluations for each model, the one with the most accurate data is k-NN algorithm, which has an accuracy of 86%. 
```
